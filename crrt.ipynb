{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%m-%d %H:%M\": \":00\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 날짜/시간 컬럼을 datetime 형식으로 변환\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df_crrt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[간호기록]기록작성일시\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_crrt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[간호기록]기록작성일시\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_merged\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mH:\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 결과를 저장할 리스트\u001b[39;00m\n\u001b[0;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1112\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    491\u001b[0m     arg,\n\u001b[0;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m )\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    509\u001b[0m     arg,\n\u001b[0;32m    510\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:359\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%m-%d %H:%M\": \":00\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 엑셀 파일 읽기\n",
    "df_crrt = pd.read_excel('CRRT_setting.xlsx')\n",
    "\n",
    "# CSV 파일 읽기 (첫 50개 행만)\n",
    "df_merged = pd.read_csv('merged_table_valid.csv', nrows=50)\n",
    "\n",
    "# 날짜/시간 컬럼을 datetime 형식으로 변환\n",
    "df_crrt['[간호기록]기록작성일시'] = pd.to_datetime(df_crrt['[간호기록]기록작성일시'])\n",
    "df_merged['Time'] = pd.to_datetime(df_merged['Time'], format='%Y-%m-%d %H:%M')\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "results = []\n",
    "\n",
    "# 시간 차이 임계값 설정 (예: 10분)\n",
    "time_threshold = timedelta(minutes=10)\n",
    "\n",
    "# 필요한 컬럼들\n",
    "required_columns = ['BFR', 'Pre', 'Replace', 'Dialysate']\n",
    "\n",
    "# merged_table_valid.csv의 각 행에 대해\n",
    "for _, merged_row in df_merged.iterrows():\n",
    "    # 필요한 모든 컬럼에 데이터가 있는지 확인\n",
    "    if all(pd.notna(merged_row[col]) for col in required_columns):\n",
    "        merged_time = merged_row['Time']\n",
    "        \n",
    "        # CRRT_setting.xlsx에서 가장 가까운 시간 찾기\n",
    "        closest_crrt_row = min(df_crrt.itertuples(), key=lambda x: abs(x._5 - merged_time))\n",
    "        \n",
    "        # 시간 차이가 임계값 이내인 경우에만 결과에 추가\n",
    "        if abs(closest_crrt_row._5 - merged_time) <= time_threshold:\n",
    "            results.append({\n",
    "                'Merged_Time': merged_time,\n",
    "                'CRRT_Time': closest_crrt_row._5,\n",
    "                'Time_Difference': abs(closest_crrt_row._5 - merged_time),\n",
    "                'Merged_Data': merged_row.to_dict(),\n",
    "                'CRRT_Data': closest_crrt_row._asdict()\n",
    "            })\n",
    "\n",
    "# 결과 출력\n",
    "for result in results:\n",
    "    print(f\"Merged Time: {result['Merged_Time']}\")\n",
    "    print(f\"CRRT Time: {result['CRRT_Time']}\")\n",
    "    print(f\"Time Difference: {result['Time_Difference']}\")\n",
    "    print(\"Merged Data:\", {k: v for k, v in result['Merged_Data'].items() if k in ['Time', 'PT_ID', 'CRRT_type', 'BFR', 'Pre', 'Replace', 'Dialysate', 'UF']})\n",
    "    print(\"CRRT Data:\", {k: v for k, v in result['CRRT_Data'].items() if k in ['_5', 'Entity', 'Attribute', 'Value']})\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('matched_data.csv', index=False)\n",
    "print(\"Results saved to 'matched_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\2881163380.py:19: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  merged_table[col] = merged_table[col].str.extract('(\\d+)').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 0개의 매칭된 데이터를 찾았습니다.\n",
      "Empty DataFrame\n",
      "Columns: [Time, PT_ID, CRRT_type, BFR, Pre, Replace, Dialysate, Matched]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 데이터 로드\n",
    "crrt_setting = pd.read_excel('CRRT_setting.xlsx')\n",
    "merged_table = pd.read_csv('merged_table_valid.csv')\n",
    "\n",
    "# 날짜/시간 형식 변환\n",
    "crrt_setting['[간호기록]기록작성일시'] = pd.to_datetime(crrt_setting['[간호기록]기록작성일시'])\n",
    "merged_table['Time'] = pd.to_datetime(merged_table['Time'])\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "crrt_setting = crrt_setting[['[간호기록]기록작성일시', 'Attribute', 'Value']]\n",
    "merged_table = merged_table[['Time', 'PT_ID', 'CRRT_type', 'BFR', 'Pre', 'Replace', 'Dialysate']]\n",
    "\n",
    "# 단위 제거 및 숫자로 변환\n",
    "for col in ['BFR', 'Pre', 'Replace', 'Dialysate']:\n",
    "    merged_table[col] = merged_table[col].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# 매칭 함수\n",
    "def find_match(row, crrt_data):\n",
    "    time = row['Time']\n",
    "    bfr = row['BFR']\n",
    "    pre = row['Pre']\n",
    "    replace = row['Replace']\n",
    "    dialysate = row['Dialysate']\n",
    "    \n",
    "    # 시간 범위 설정 (예: 3시간)\n",
    "    time_range = timedelta(hours=20)\n",
    "    \n",
    "    # 시간 범위 내의 CRRT 설정 데이터 필터링\n",
    "    filtered_crrt = crrt_data[(crrt_data['[간호기록]기록작성일시'] >= time - time_range) &\n",
    "                              (crrt_data['[간호기록]기록작성일시'] <= time + time_range)]\n",
    "    \n",
    "    # 각 항목별 매칭 확인\n",
    "    bfr_match = filtered_crrt[(filtered_crrt['Attribute'] == '투석 blood flow rate') & (filtered_crrt['Value'] == bfr)]\n",
    "    pre_match = filtered_crrt[(filtered_crrt['Attribute'] == '투석 replacement(전희석)') & (filtered_crrt['Value'] == pre)]\n",
    "    replace_match = filtered_crrt[(filtered_crrt['Attribute'] == '투석 replacement(후희석)') & (filtered_crrt['Value'] == replace)]\n",
    "    dialysate_match = filtered_crrt[(filtered_crrt['Attribute'] == '투석 dialysate') & (filtered_crrt['Value'] == dialysate)]\n",
    "    \n",
    "    # 매칭 개수 확인\n",
    "    match_count = sum([len(bfr_match) > 0, len(pre_match) > 0, len(replace_match) > 0, len(dialysate_match) > 0])\n",
    "    \n",
    "    if match_count >= 2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 매칭 적용\n",
    "merged_table['Matched'] = merged_table.apply(lambda row: find_match(row, crrt_setting) if pd.notnull(row['BFR']) and pd.notnull(row['Pre']) and pd.notnull(row['Replace']) and pd.notnull(row['Dialysate']) else False, axis=1)\n",
    "\n",
    "# 결과 출력\n",
    "matched_data = merged_table[merged_table['Matched']]\n",
    "print(f\"총 {len(matched_data)}개의 매칭된 데이터를 찾았습니다.\")\n",
    "print(matched_data)\n",
    "\n",
    "# 결과 저장\n",
    "matched_data.to_csv('matched_crrt_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRRT_setting.xlsx의 '[간호기록]기록작성일시' 데이터 (처음 20개):\n",
      "2021-07-06 07:00:00\n",
      "2021-07-06 08:25:00\n",
      "2021-07-06 11:56:00\n",
      "2021-07-06 16:00:00\n",
      "2021-07-07 00:00:00\n",
      "2021-07-07 08:00:00\n",
      "2021-07-07 14:00:00\n",
      "2021-07-08 21:15:00\n",
      "2021-07-08 21:30:00\n",
      "2021-07-08 23:00:00\n",
      "2021-07-09 00:00:00\n",
      "2021-07-09 01:08:00\n",
      "2021-07-09 01:30:00\n",
      "2021-07-09 05:23:00\n",
      "2021-07-09 06:00:00\n",
      "2021-07-09 06:30:00\n",
      "2021-07-09 07:00:00\n",
      "2021-07-09 07:30:00\n",
      "2021-07-09 08:00:00\n",
      "2021-07-09 10:00:00\n",
      "\n",
      "총 고유 시간 개수: 17296\n",
      "\n",
      "시간 범위:\n",
      "시작: 2021-07-06 07:00:00\n",
      "종료: 2022-08-15 03:35:00\n",
      "\n",
      "\n",
      "merged_table_valid.csv의 'Time' 데이터 (처음 20개):\n",
      "2022-02-06 21:29:00\n",
      "2022-02-07 10:43:00\n",
      "2022-02-07 12:25:00\n",
      "2022-02-07 13:13:00\n",
      "2022-02-07 13:55:00\n",
      "2022-02-07 14:22:00\n",
      "2022-02-07 14:55:00\n",
      "2022-02-07 15:51:00\n",
      "2022-02-07 15:57:00\n",
      "2022-02-07 16:50:00\n",
      "2022-02-07 17:16:00\n",
      "2022-02-07 17:25:00\n",
      "2022-02-07 18:43:00\n",
      "2022-02-07 18:52:00\n",
      "2022-02-07 20:20:00\n",
      "2022-02-07 21:51:00\n",
      "2022-02-08 00:56:00\n",
      "2022-02-08 02:02:00\n",
      "2022-02-08 05:51:00\n",
      "2022-02-08 15:54:00\n",
      "\n",
      "총 고유 시간 개수: 1096\n",
      "\n",
      "시간 범위:\n",
      "시작: 2022-02-06 21:29:00\n",
      "종료: 2022-05-22 07:32:00\n",
      "\n",
      "\n",
      "두 데이터셋의 시간 범위 비교:\n",
      "CRRT_setting: 2021-07-06 07:00:00 to 2022-08-15 03:35:00\n",
      "merged_table: 2022-02-06 21:29:00 to 2022-05-22 07:32:00\n",
      "\n",
      "시간 범위 겹침: 예\n",
      "\n",
      "전체 시간 데이터를 'crrt_setting_times.csv'와 'merged_table_times.csv' 파일로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "crrt_setting = pd.read_excel('CRRT_setting.xlsx')\n",
    "merged_table = pd.read_csv('merged_table_valid.csv')\n",
    "\n",
    "# 날짜/시간 형식 변환\n",
    "crrt_setting['[간호기록]기록작성일시'] = pd.to_datetime(crrt_setting['[간호기록]기록작성일시'])\n",
    "merged_table['Time'] = pd.to_datetime(merged_table['Time'])\n",
    "\n",
    "# CRRT_setting 데이터의 시간을 정렬하고 중복 제거\n",
    "crrt_times = crrt_setting['[간호기록]기록작성일시'].sort_values().drop_duplicates()\n",
    "\n",
    "# merged_table 데이터의 시간을 정렬하고 중복 제거\n",
    "merged_times = merged_table['Time'].sort_values().drop_duplicates()\n",
    "\n",
    "print(\"CRRT_setting.xlsx의 '[간호기록]기록작성일시' 데이터 (처음 20개):\")\n",
    "print(crrt_times.head(20).to_string(index=False))\n",
    "print(\"\\n총 고유 시간 개수:\", len(crrt_times))\n",
    "print(\"\\n시간 범위:\")\n",
    "print(f\"시작: {crrt_times.min()}\")\n",
    "print(f\"종료: {crrt_times.max()}\")\n",
    "\n",
    "print(\"\\n\\nmerged_table_valid.csv의 'Time' 데이터 (처음 20개):\")\n",
    "print(merged_times.head(20).to_string(index=False))\n",
    "print(\"\\n총 고유 시간 개수:\", len(merged_times))\n",
    "print(\"\\n시간 범위:\")\n",
    "print(f\"시작: {merged_times.min()}\")\n",
    "print(f\"종료: {merged_times.max()}\")\n",
    "\n",
    "# 두 데이터셋의 시간 범위 비교\n",
    "print(\"\\n\\n두 데이터셋의 시간 범위 비교:\")\n",
    "print(f\"CRRT_setting: {crrt_times.min()} to {crrt_times.max()}\")\n",
    "print(f\"merged_table: {merged_times.min()} to {merged_times.max()}\")\n",
    "\n",
    "# 시간 범위 겹치는지 확인\n",
    "overlap = (crrt_times.min() <= merged_times.max()) and (merged_times.min() <= crrt_times.max())\n",
    "print(f\"\\n시간 범위 겹침: {'예' if overlap else '아니오'}\")\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "crrt_times.to_csv('crrt_setting_times.csv', index=False, header=['Time'])\n",
    "merged_times.to_csv('merged_table_times.csv', index=False, header=['Time'])\n",
    "print(\"\\n전체 시간 데이터를 'crrt_setting_times.csv'와 'merged_table_times.csv' 파일로 저장했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "날짜/시간 형식 변환 중...\n",
      "시간 매칭 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 79/1224 [00:50<12:11,  1.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# merged_table의 각 시간에 대해 CRRT_setting에서 가장 가까운 시간 찾기\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간 매칭 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m merged_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched_Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_closest_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrrt_setting\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[간호기록]기록작성일시\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 매칭된 결과 분석\u001b[39;00m\n\u001b[0;32m     32\u001b[0m matched_data \u001b[38;5;241m=\u001b[39m merged_table\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched_Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tqdm\\std.py:920\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    922\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    916\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:80\u001b[0m, in \u001b[0;36mravel_compat.<locals>.method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(meth)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray\u001b[38;5;241m.\u001b[39mflags\n\u001b[0;32m     83\u001b[0m     flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mravel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:723\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.map\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;129m@ravel_compat\u001b[39m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Index\n\u001b[1;32m--> 723\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m     result \u001b[38;5;241m=\u001b[39m Index(result)\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, ABCMultiIndex):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\tqdm\\std.py:915\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    913\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    914\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# merged_table의 각 시간에 대해 CRRT_setting에서 가장 가까운 시간 찾기\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m시간 매칭 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m merged_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched_Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_table[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfind_closest_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrrt_setting\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[간호기록]기록작성일시\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 매칭된 결과 분석\u001b[39;00m\n\u001b[0;32m     32\u001b[0m matched_data \u001b[38;5;241m=\u001b[39m merged_table\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched_Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m, in \u001b[0;36mfind_closest_time\u001b[1;34m(target_time, time_series, max_diff)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_closest_time\u001b[39m(target_time, time_series, max_diff\u001b[38;5;241m=\u001b[39mtimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m---> 20\u001b[0m     closest_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(closest_time \u001b[38;5;241m-\u001b[39m target_time) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_diff:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m closest_time\n",
      "Cell \u001b[1;32mIn[19], line 20\u001b[0m, in \u001b[0;36mfind_closest_time.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_closest_time\u001b[39m(target_time, time_series, max_diff\u001b[38;5;241m=\u001b[39mtimedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m---> 20\u001b[0m     closest_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(time_series, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(x \u001b[38;5;241m-\u001b[39m target_time))\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(closest_time \u001b[38;5;241m-\u001b[39m target_time) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_diff:\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m closest_time\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm을 pandas 연산에 적용\n",
    "tqdm.pandas()\n",
    "\n",
    "# 데이터 로드\n",
    "print(\"데이터 로딩 중...\")\n",
    "crrt_setting = pd.read_excel('CRRT_setting.xlsx')\n",
    "merged_table = pd.read_csv('merged_table_valid.csv')\n",
    "\n",
    "# 날짜/시간 형식 변환\n",
    "print(\"날짜/시간 형식 변환 중...\")\n",
    "crrt_setting['[간호기록]기록작성일시'] = pd.to_datetime(crrt_setting['[간호기록]기록작성일시'])\n",
    "merged_table['Time'] = pd.to_datetime(merged_table['Time'])\n",
    "\n",
    "# 시간 매칭 함수\n",
    "def find_closest_time(target_time, time_series, max_diff=timedelta(hours=3)):\n",
    "    closest_time = min(time_series, key=lambda x: abs(x - target_time))\n",
    "    if abs(closest_time - target_time) <= max_diff:\n",
    "        return closest_time\n",
    "    return pd.NaT\n",
    "\n",
    "# merged_table의 각 시간에 대해 CRRT_setting에서 가장 가까운 시간 찾기\n",
    "print(\"시간 매칭 중...\")\n",
    "merged_table['Matched_Time'] = merged_table['Time'].progress_apply(\n",
    "    lambda x: find_closest_time(x, crrt_setting['[간호기록]기록작성일시'])\n",
    ")\n",
    "\n",
    "# 매칭된 결과 분석\n",
    "matched_data = merged_table.dropna(subset=['Matched_Time'])\n",
    "print(f\"\\n총 {len(matched_data)}개의 매칭된 데이터를 찾았습니다.\")\n",
    "\n",
    "# 시간 차이 계산\n",
    "print(\"시간 차이 계산 중...\")\n",
    "matched_data['Time_Difference'] = (matched_data['Matched_Time'] - matched_data['Time']).abs()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n매칭된 데이터 샘플 (처음 10개):\")\n",
    "print(matched_data[['Time', 'Matched_Time', 'Time_Difference', 'BFR', 'Pre', 'Replace', 'Dialysate']].head(10))\n",
    "\n",
    "print(\"\\n시간 차이 통계:\")\n",
    "print(matched_data['Time_Difference'].describe())\n",
    "\n",
    "# 매칭된 데이터와 원본 CRRT_setting 데이터 병합\n",
    "print(\"데이터 병합 중...\")\n",
    "merged_result = pd.merge(\n",
    "    matched_data, \n",
    "    crrt_setting, \n",
    "    left_on='Matched_Time', \n",
    "    right_on='[간호기록]기록작성일시',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 결과 저장\n",
    "print(\"결과 저장 중...\")\n",
    "merged_result.to_csv('matched_crrt_data_with_tolerance.csv', index=False)\n",
    "print(\"매칭된 데이터를 'matched_crrt_data_with_tolerance.csv' 파일로 저장했습니다.\")\n",
    "\n",
    "# 매칭되지 않은 데이터 분석\n",
    "unmatched_data = merged_table[merged_table['Matched_Time'].isna()]\n",
    "print(f\"\\n매칭되지 않은 데이터: {len(unmatched_data)}개\")\n",
    "\n",
    "if not unmatched_data.empty:\n",
    "    print(\"\\n매칭되지 않은 데이터 샘플 (처음 5개):\")\n",
    "    print(unmatched_data[['Time', 'BFR', 'Pre', 'Replace', 'Dialysate']].head())\n",
    "\n",
    "# CRRT_setting에서 사용되지 않은 시간 분석\n",
    "used_times = set(merged_result['[간호기록]기록작성일시'])\n",
    "unused_times = crrt_setting[~crrt_setting['[간호기록]기록작성일시'].isin(used_times)]\n",
    "print(f\"\\nCRRT_setting에서 매칭에 사용되지 않은 시간: {len(unused_times)}개\")\n",
    "\n",
    "if not unused_times.empty:\n",
    "    print(\"\\n사용되지 않은 시간 샘플 (처음 5개):\")\n",
    "    print(unused_times['[간호기록]기록작성일시'].head())\n",
    "\n",
    "print(\"\\n처리 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜/시간 형식 변환 중...\n",
      "필터링 후 남은 데이터: 114행\n",
      "시간 매칭 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:57<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "총 113개의 매칭된 데이터를 찾았습니다.\n",
      "시간 차이 계산 중...\n",
      "\n",
      "매칭된 데이터 샘플 (처음 5개):\n",
      "                  Time        Matched_Time Time_Difference    BFR     Pre  \\\n",
      "0  2022-02-06 21:29:00 2022-02-06 21:30:00 0 days 00:01:00  120.0  1000.0   \n",
      "24 2022-02-08 16:42:00 2022-02-08 16:30:00 0 days 00:12:00  120.0   650.0   \n",
      "38 2022-02-09 01:11:00 2022-02-09 01:00:00 0 days 00:11:00  120.0   650.0   \n",
      "49 2022-02-09 13:13:00 2022-02-09 13:01:00 0 days 00:12:00  120.0   650.0   \n",
      "58 2022-02-10 10:01:00 2022-02-10 10:00:00 0 days 00:01:00  120.0   650.0   \n",
      "\n",
      "    Replace  Dialysate  \n",
      "0     200.0     1200.0  \n",
      "24    200.0      850.0  \n",
      "38    200.0      850.0  \n",
      "49    200.0      850.0  \n",
      "58    200.0      850.0  \n",
      "\n",
      "시간 차이 통계:\n",
      "count                          113\n",
      "mean     0 days 00:07:16.991150442\n",
      "std      0 days 00:07:46.860496439\n",
      "min                0 days 00:00:00\n",
      "25%                0 days 00:02:00\n",
      "50%                0 days 00:05:00\n",
      "75%                0 days 00:11:00\n",
      "max                0 days 00:50:00\n",
      "Name: Time_Difference, dtype: object\n",
      "데이터 병합 중...\n",
      "\n",
      "최종 매칭 결과 샘플 (처음 5개):\n",
      "                 Time        Matched_Time Time_Difference    BFR     Pre  \\\n",
      "0 2022-02-06 21:29:00 2022-02-06 21:30:00 0 days 00:01:00  120.0  1000.0   \n",
      "1 2022-02-06 21:29:00 2022-02-06 21:30:00 0 days 00:01:00  120.0  1000.0   \n",
      "2 2022-02-06 21:29:00 2022-02-06 21:30:00 0 days 00:01:00  120.0  1000.0   \n",
      "3 2022-02-08 16:42:00 2022-02-08 16:30:00 0 days 00:12:00  120.0   650.0   \n",
      "4 2022-02-08 16:42:00 2022-02-08 16:30:00 0 days 00:12:00  120.0   650.0   \n",
      "\n",
      "   Replace  Dialysate              Attribute                      Value  \n",
      "0    200.0     1200.0  투석 preblood pump rate  phoxilium 5L+Bivon 4@ mix  \n",
      "1    200.0     1200.0    투석 replacement(전희석)  phoxilium 5L+Bivon 4@ mix  \n",
      "2    200.0     1200.0           투석 dialysate  phoxilium 5L+Bivon 4@ mix  \n",
      "3    200.0      850.0  투석 preblood pump rate                        900  \n",
      "4    200.0      850.0    투석 replacement(후희석)                        300  \n",
      "\n",
      "매칭되지 않은 데이터: 1개\n",
      "\n",
      "매칭되지 않은 데이터 샘플 (처음 5개):\n",
      "                   Time    BFR    Pre  Replace  Dialysate\n",
      "753 2022-04-10 07:44:00  120.0  600.0    200.0      800.0\n",
      "\n",
      "결과를 CSV 파일로 저장 중...\n",
      "매칭된 데이터를 'matched_crrt_data_filtered.csv' 파일로 저장했습니다. (UTF-8 인코딩)\n",
      "\n",
      "처리 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_table_filtered['Matched_Time'] = merged_table_filtered['Time'].progress_apply(\n",
      "C:\\Users\\SNUH\\AppData\\Local\\Temp\\ipykernel_18936\\3672733975.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched_data['Time_Difference'] = (matched_data['Matched_Time'] - matched_data['Time']).abs()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm을 pandas 연산에 적용\n",
    "tqdm.pandas()\n",
    "\n",
    "# 데이터 로드\n",
    "print(\"데이터 로딩 중...\")\n",
    "crrt_setting = pd.read_excel('CRRT_setting.xlsx')\n",
    "merged_table = pd.read_csv('merged_table_valid.csv')\n",
    "\n",
    "# 날짜/시간 형식 변환\n",
    "print(\"날짜/시간 형식 변환 중...\")\n",
    "crrt_setting['[간호기록]기록작성일시'] = pd.to_datetime(crrt_setting['[간호기록]기록작성일시'])\n",
    "merged_table['Time'] = pd.to_datetime(merged_table['Time'])\n",
    "\n",
    "# BFR, Pre, Replace, Dialysate 컬럼에 모두 값이 있는 행만 선택\n",
    "columns_to_check = ['BFR', 'Pre', 'Replace', 'Dialysate']\n",
    "merged_table_filtered = merged_table.dropna(subset=columns_to_check)\n",
    "\n",
    "# ml/min, ml/h 단위 제거 및 숫자로 변환\n",
    "for col in columns_to_check:\n",
    "    merged_table_filtered[col] = merged_table_filtered[col].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "print(f\"필터링 후 남은 데이터: {len(merged_table_filtered)}행\")\n",
    "\n",
    "# 시간 매칭 함수\n",
    "def find_closest_time(target_time, time_series, max_diff=timedelta(hours=3)):\n",
    "    closest_time = min(time_series, key=lambda x: abs(x - target_time))\n",
    "    if abs(closest_time - target_time) <= max_diff:\n",
    "        return closest_time\n",
    "    return pd.NaT\n",
    "\n",
    "# merged_table의 각 시간에 대해 CRRT_setting에서 가장 가까운 시간 찾기\n",
    "print(\"시간 매칭 중...\")\n",
    "merged_table_filtered['Matched_Time'] = merged_table_filtered['Time'].progress_apply(\n",
    "    lambda x: find_closest_time(x, crrt_setting['[간호기록]기록작성일시'])\n",
    ")\n",
    "\n",
    "# 매칭된 결과 분석\n",
    "matched_data = merged_table_filtered.dropna(subset=['Matched_Time'])\n",
    "print(f\"\\n총 {len(matched_data)}개의 매칭된 데이터를 찾았습니다.\")\n",
    "\n",
    "# 시간 차이 계산\n",
    "print(\"시간 차이 계산 중...\")\n",
    "matched_data['Time_Difference'] = (matched_data['Matched_Time'] - matched_data['Time']).abs()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n매칭된 데이터 샘플 (처음 5개):\")\n",
    "print(matched_data[['Time', 'Matched_Time', 'Time_Difference', 'BFR', 'Pre', 'Replace', 'Dialysate']].head())\n",
    "\n",
    "print(\"\\n시간 차이 통계:\")\n",
    "print(matched_data['Time_Difference'].describe())\n",
    "\n",
    "# 매칭된 데이터와 원본 CRRT_setting 데이터 병합\n",
    "print(\"데이터 병합 중...\")\n",
    "merged_result = pd.merge(\n",
    "    matched_data, \n",
    "    crrt_setting, \n",
    "    left_on='Matched_Time', \n",
    "    right_on='[간호기록]기록작성일시',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n최종 매칭 결과 샘플 (처음 5개):\")\n",
    "print(merged_result[['Time', 'Matched_Time', 'Time_Difference', 'BFR', 'Pre', 'Replace', 'Dialysate', 'Attribute', 'Value']].head())\n",
    "\n",
    "# 매칭되지 않은 데이터 분석\n",
    "unmatched_data = merged_table_filtered[merged_table_filtered['Matched_Time'].isna()]\n",
    "print(f\"\\n매칭되지 않은 데이터: {len(unmatched_data)}개\")\n",
    "\n",
    "if not unmatched_data.empty:\n",
    "    print(\"\\n매칭되지 않은 데이터 샘플 (처음 5개):\")\n",
    "    print(unmatched_data[['Time', 'BFR', 'Pre', 'Replace', 'Dialysate']].head())\n",
    "\n",
    "# 결과 저장 (UTF-8 인코딩 적용)\n",
    "print(\"\\n결과를 CSV 파일로 저장 중...\")\n",
    "merged_result.to_csv('matched_crrt_data_filtered.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"매칭된 데이터를 'matched_crrt_data_filtered.csv' 파일로 저장했습니다. (UTF-8 인코딩)\")\n",
    "\n",
    "print(\"\\n처리 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
